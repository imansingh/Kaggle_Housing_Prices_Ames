{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project_3: Linear Regressions\n",
    "## Author: Wing Yan Sang\n",
    "## Date: 11/5/2017\n",
    "\n",
    "<p><a name=\"sections\"></a></p>\n",
    "\n",
    "\n",
    "## Sections\n",
    "\n",
    "- <a href=\"#numeric\">EDA of Numerics</a><br>\n",
    "- <a href=\"#linear1\">Linear Regression 1</a><br>\n",
    "- <a href=\"#categorical\">EDA of Categoricals</a><br>\n",
    "- <a href=\"#categorica_engineering\">Features Engineering of Select Categoricals</a><br>\n",
    "- <a href=\"#linear2\">Linear Regression 2</a><br>\n",
    "- <a href=\"#VIF1\">VIF Analysis of Linear Regression 2 Model</a><br>\n",
    "- <a href=\"#linear3\">Linear Regression 3</a><br>\n",
    "- <a href=\"#linear4\">Linear Regression 4</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a228910fa33b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimpute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderived_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteract_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_vars_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_vars_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'preprocess'"
     ]
    }
   ],
   "source": [
    "# Loading the packages to be used\n",
    "from __future__ import print_function \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from  statsmodels.genmod import generalized_linear_model\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from preprocess import impute, derived_vars, interact_vars, select_vars_train, select_vars_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in csv file and create data frame\n",
    "train_df = pd.read_csv('./Pyhon/train.csv')\n",
    "test_df = pd.read_csv('./Pyhon/test.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#impute missing variables\n",
    "train_data_imputed = impute(train_df)\n",
    "test_data_imputed = impute(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in csv file and create data frame\n",
    "train_sub = pd.read_csv(\".Pyhon/train_sub.csv\")\n",
    "train_sub = pd.DataFrame(train_sub)\n",
    "pd.set_option('display.max_columns', None)\n",
    "train_sub.head()\n",
    "\n",
    "#drop columns: \"X1stFlrSF, X2ndFlrSF, GarageQual, GarageCond, PavedDrive\n",
    "train_sub = train_sub.drop([\"X1stFlrSF\", \"X2ndFlrSF\", \"GarageQual\", \"GarageCond\", \"PavedDrive\"], 1)\n",
    "train_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split into numeric and categorical features and observed values\n",
    "X_num = train_sub[[\"GrLivArea\", \"FullBath\", \"TotRmsAbvGrd\", \"GarageCars\", \"GarageArea\"]]\n",
    "X_cat = train_sub.drop([\"GrLivArea\", \"FullBath\", \"TotRmsAbvGrd\", \"GarageCars\", \"GarageArea\", \"SalePrice\"],1)\n",
    "y = train_sub[[\"SalePrice\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inspect distribution of sales prices. Seems that log transformation can make the sales price more \"normal\".\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "prices = pd.DataFrame({\"price\":y[\"SalePrice\"], \"log(price + 1)\":np.log1p(y[\"SalePrice\"])})\n",
    "prices.hist()\n",
    "\n",
    "#log transform the target:\n",
    "y = np.log1p(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"numeric\"></a></p>\n",
    "\n",
    "## EDA of Numeric Variables\n",
    "\n",
    "EDA of the following Numeric Variables: \"GrLivArea\", \"FullBath\", \"TotRmsAbvGrd\", \"GarageCars\", \"GarageArea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inspect summary of numeric variables\n",
    "X_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check for multicollinearity between GarageArea and GrLivArea. Scatter shows vague linear relationship. \n",
    "#Correlation is 0.46899\n",
    "\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(X_num[[\"GarageArea\",\"GrLivArea\"]], alpha=0.2, figsize=(12, 12), diagonal='kde')\n",
    "plt.savefig('num_scatter.png')\n",
    "np.corrcoef(X_num[\"GarageArea\"], X_num[\"GrLivArea\"])[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check for multicollinearity between GarageArea with other variables (except GrLivarea) using boxplots.\n",
    "#There does seem to be a linear relationship between Garage Area and these other variables.\n",
    "#All seem pretty strong.\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "for i in range(1,4):\n",
    "    sns.boxplot(y=X_num[\"GarageArea\"], x=X_num.iloc[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check for multicollinearity between GrLivArea with other variables (except GrLivarea) using boxplots.\n",
    "#There does seem to be a linear relationship between GrLiv Area and these other variables.\n",
    "#TotRms and Full Bath are strongest.\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "for i in range(1,4):\n",
    "    sns.boxplot(y=X_num[\"GrLivArea\"], x=X_num.iloc[:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"linear1\"></a></p>\n",
    "## Linear Regression 1\n",
    "\n",
    "First linear regression with the following variables: \"GrLivArea\", \"GarageCars\", \"GarageArea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split into training and test sets\n",
    "\n",
    "X = X_num[[\"GrLivArea\", \"GarageCars\",\"GarageArea\"]]\n",
    "\n",
    "try:  # train_test_split was moved in 0.18.0\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except:  # Following import works through 0.19 but outputs a warning in 0.18\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run linear model with just GrLivArea, GarageCars, GrLivArea\n",
    "#RMSE goes up for test set. May have overfitted the model. Also the RMSE and R^2 results are not that good.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "ols = linear_model.LinearRegression()\n",
    "\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "y_predicted_train = ols.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_predicted)\n",
    "rms_train = sqrt(mean_squared_error(y_train, y_predicted_train))\n",
    "\n",
    "y_predicted_test = ols.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_predicted_test)\n",
    "rms_test = sqrt(mean_squared_error(y_test, y_predicted_test))\n",
    "\n",
    "print(\"Root mean squared error for train set: %f\" %rms_train)\n",
    "print(\"R^2 for train set: %f\" %ols.score(X_train, y_train))\n",
    "\n",
    "print(\"*\"*50)\n",
    "\n",
    "print(\"Root mean squared error for test set: %f\" %rms_test)\n",
    "print(\"R^2 for test  set: %f\" %ols.score(X_test, y_test))\n",
    "\n",
    "colnames = X_train.columns\n",
    "result = pd.DataFrame(ols.coef_)\n",
    "result.columns = colnames.tolist()\n",
    "result['intercept'] = ols.intercept_ \n",
    "result = result.transpose()\n",
    "result.columns = ['coefficient']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Performing same analysis as above using Statsmodel\n",
    "X_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = sm.add_constant(X_test)\n",
    "y_predicted_test = results.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_predicted_test)\n",
    "rms_test = sqrt(mean_squared_error(y_test, y_predicted_test))\n",
    "print(\"Root mean squared error for test set: %f\" %rms_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"categorical\"></a></p>\n",
    "\n",
    "## EDA of Categorical Variables\n",
    "\n",
    "EDA of categorical variables to examine relationship with SalePrice and with each other. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#View the Categorical Variables\n",
    "X_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Bar charts of the categorical variables\n",
    "#For quality variables, the middle value (typical) dominates, then the second is good.\n",
    "#GarageFinish is dominated by Unfinished and Rough Finish\n",
    "#HouseStyle can be broken up into >=2Flr, <=1 1Flr, SplitLevel\n",
    "#MSZoning dominated by Residential(Low and Medium Density)\n",
    "#Will need to do further analysis on Neighborhood to see if it values can be combined.\n",
    "#Sale Type/SaleCondition dominated by Warranty Deed and Normal\n",
    "#Many homes built after 1990\n",
    "\n",
    "for idx, col in zip(range(1, len(X_cat.columns)),X_cat.columns.sort_values()): \n",
    "    plt.figure(figsize=(8, 10)) \n",
    "    X_cat[col].value_counts().plot(kind='bar', )\n",
    "    plt.title(col) \n",
    "    plt.show()\n",
    "    \n",
    "plt.hist(X_cat[\"YearBuilt\"], bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"categorical_engineering\"></a></p>\n",
    "\n",
    "## EDA and Features Engineering of Select Categorical Variables\n",
    "\n",
    "EDA and features engineering of the following categorical variables:\n",
    "\"Neighborhood\", \"OverallQual\", \"HouseStyle\", \"SaleCondition\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Boxplot of sales price by neighborhood. \n",
    "#Seems like there are big ranges for neighborhoods at the top end of the market whereas ranges are smaller \n",
    "#at bottom neighborhoods. Also there are quite a few outliers. May have to remove them to prevent overfitting.\n",
    "\n",
    "m = train_sub.groupby(['Neighborhood'])['SalePrice'].apply(np.median)\n",
    "m.name = 'MEDIAN'\n",
    "m = m.sort_values()\n",
    "m.index\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "sns.boxplot(y=train_sub[\"SalePrice\"], x=train_sub[\"Neighborhood\"], order = m.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Examine quartile ranges and group them\n",
    "pd.qcut(m, 4)\n",
    "x = pd.DataFrame(pd.qcut(m, 4))\n",
    "x.columns.values[0] = \"quartiles\"\n",
    "s = [i for i in range(1,5) for _ in range(6)]\n",
    "s.insert(0,1)\n",
    "x[\"Group\"] = s\n",
    "x.columns.values[1] = \"Neigh_Group\"\n",
    "x['Neighborhood'] = x.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add Neigh_Group column to train_sub data frame. Count the frequency of each group. \n",
    "#Lower value homes most frequent. Higher valued homes least frequent.\n",
    "\n",
    "new_df = pd.merge(train_sub, x, how='left', on = [\"Neighborhood\", \"Neighborhood\"])\n",
    "new_df = new_df.drop(\"quartiles\",1)\n",
    "train_sub = new_df\n",
    "train_sub.groupby(\"Neigh_Group\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Group HouseStyle variable by 1stFloor, 2ndFloor, and Split and count frequency. 1Story and 2Story close.\n",
    "\n",
    "def hstyle(c):\n",
    "    if c['HouseStyle'] == \"1Story\":\n",
    "        return '1Story'\n",
    "    elif c['HouseStyle'] in [\"SFoyer\", \"SLvl\"]:\n",
    "        return 'Split'\n",
    "    else:\n",
    "        return '2Story'\n",
    "\n",
    "train_sub['House_Group'] = train_sub.apply(hstyle, axis=1)\n",
    "train_sub.groupby(\"House_Group\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Boxplot of sales price by OverallQual. As quality goes up, sales price goes up.\n",
    "#Similar to Neighborhood analysis, there are bigger ranges the higher the quality. \n",
    "#Also there are quite a few outliers towards right side of chart.\n",
    "\n",
    "n = train_sub.groupby(['OverallQual'])['SalePrice'].apply(np.median)\n",
    "n.name = 'MEDIAN'\n",
    "n = n.sort_values()\n",
    "n.index\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "sns.boxplot(y=train_sub[\"SalePrice\"], x=train_sub[\"OverallQual\"], order = n.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Examine relationship between Neighborhood, OverallQual, and SalePrice. Lower quality (olive green, green) \n",
    "#corresponds to lower price and certain neigborhoods. Same for higher quality homes (violet, pinkish, light blue).\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.swarmplot(x = 'Neighborhood', y = 'SalePrice', data=train_sub, hue='OverallQual',order = m.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Crosstab also shows some relationship between the Neigh_Group and OverallQual\n",
    "\n",
    "pd.crosstab(train_sub[\"Neigh_Group\"], train_sub[\"OverallQual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Examine the quantiles of OverallQual\n",
    "qual_cut = pd.DataFrame(pd.qcut(n, 3))\n",
    "qual_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add column that groups OverallQual into thirds\n",
    "\n",
    "def overall_qual(c):\n",
    "    if c['OverallQual'] <= 4:\n",
    "        return 'Low'\n",
    "    elif c['OverallQual'] > 7:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Medium'\n",
    "\n",
    "train_sub['Qual_Group'] = train_sub.apply(overall_qual, axis=1)\n",
    "train_sub.groupby(\"Qual_Group\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Boxplot of sales price by SaleCondition. \n",
    "\n",
    "n2 = train_sub.groupby(['SaleCondition'])['SalePrice'].apply(np.median)\n",
    "n2.name = 'MEDIAN'\n",
    "n2 = n2.sort_values()\n",
    "n2.index\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "sns.boxplot(y=train_sub[\"SalePrice\"], x=train_sub[\"SaleCondition\"], order = n2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Examine the quantiles of OverallQual\n",
    "pd.qcut(n2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add column that groups SaleCondition into thirds\n",
    "\n",
    "def saleCond(c):\n",
    "    if c['SaleCondition'] == \"Partial\":\n",
    "        return 'Partial'\n",
    "    else:\n",
    "        return 'Non_partial'\n",
    "\n",
    "train_sub['SaleCond_Group'] = train_sub.apply(saleCond, axis=1)\n",
    "train_sub.groupby(\"SaleCond_Group\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dummify Neigh_Group\n",
    "df = train_sub.copy()\n",
    "hood = pd.get_dummies(df['Neigh_Group'], prefix='Neigh', prefix_sep='__')\n",
    "hood = hood.drop('Neigh__1', axis=1)\n",
    "hood.head()\n",
    "df = pd.concat([df.drop('Neigh_Group', axis=1), hood], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dummify HouseStyle\n",
    "df = df.copy()\n",
    "style = pd.get_dummies(df['House_Group'], prefix='Style', prefix_sep='__')\n",
    "style = style.drop('Style__1Story', axis=1)\n",
    "df = pd.concat([df.drop('House_Group', axis=1), style], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dummify OverallQual\n",
    "df = df.copy()\n",
    "qual = pd.get_dummies(df['Qual_Group'], prefix='Qual', prefix_sep='__')\n",
    "qual = qual.drop('Qual__Low', axis=1)\n",
    "df = pd.concat([df.drop('Qual_Group', axis=1), qual], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dummify SaleCond\n",
    "df = df.copy()\n",
    "saleCond = pd.get_dummies(df['SaleCond_Group'], prefix='saleCond', prefix_sep='__')\n",
    "saleCond = saleCond.drop('saleCond__Non_partial', axis=1)\n",
    "df = pd.concat([df.drop('SaleCond_Group', axis=1), saleCond], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"linear2\"></a></p>\n",
    "\n",
    "## Linear Regression 2\n",
    "\n",
    "Linear regression using the following variables: \"GrLivArea\", \"Neighborhood\", \"OverallQual\", \n",
    "\"HouseStyle\", \"SaleCondition\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select five variables to perform linear regression\n",
    "X = pd.concat([df[[\"GrLivArea\"]],df[df.columns[-8:]]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split train_sub into train and test and fit 2nd linear model on train:\n",
    "\n",
    "try:  # train_test_split was moved in 0.18.0\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except:  # Following import works through 0.19 but outputs a warning in 0.18\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fit 2nd linear model to train set and test against test set\n",
    "#Results better than first model. RMSE does not change that much between train and test set.\n",
    "\n",
    "ols = linear_model.LinearRegression()\n",
    "\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "y_predicted_train = ols.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_predicted)\n",
    "rms_train = sqrt(mean_squared_error(y_train, y_predicted_train))\n",
    "\n",
    "y_predicted_test = ols.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_predicted_test)\n",
    "rms_test = sqrt(mean_squared_error(y_test, y_predicted_test))\n",
    "\n",
    "print(\"Root mean squared error for train set: %f\" %rms_train)\n",
    "print(\"R^2 for train set: %f\" %ols.score(X_train, y_train))\n",
    "\n",
    "print(\"*\"*50)\n",
    "\n",
    "print(\"Root mean squared error for test set: %f\" %rms_test)\n",
    "print(\"R^2 for test  set: %f\" %ols.score(X_test, y_test))\n",
    "\n",
    "colnames = X_train.columns\n",
    "result = pd.DataFrame(ols.coef_)\n",
    "result.columns = colnames.tolist()\n",
    "result['intercept'] = ols.intercept_ \n",
    "result = result.transpose()\n",
    "result.columns = ['coefficient']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Performing same analysis as above using Statsmodel. Notice AIC and BIC better than 1st linear regression model.\n",
    "X_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"VIF1\"></a></p>\n",
    "\n",
    "## VIF Analysis of Variables in Linear Regression 2\n",
    "\n",
    "The output of the Statsmodel makes it clear that multicollinearity may be an issue with the model. \n",
    "The following is a VIF analysis to assess which variables might be contributing the most to the VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the VIFs (not dependent on model fit). VIFs for GrLivArea and Qual_Medium are very high.\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = [variance_inflation_factor(X_train.drop(\"const\", axis =1).values, i) for \n",
    "       i in range(X_train.drop(\"const\", axis =1).shape[1])]\n",
    "list(zip(vif, X_train.drop(\"const\",axis=1).columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dropping GrLivArea reduces the VIF for all the variables. \n",
    "X_reduced = X_train.drop([\"const\",\"GrLivArea\"], axis =1)\n",
    "vif = [variance_inflation_factor(X_reduced.values, i) for \n",
    "       i in range(X_reduced.shape[1])]\n",
    "print(\"VIF for all the variables:\")\n",
    "list(zip(vif, X_reduced.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"linear3\"></a></p>\n",
    "\n",
    "## Linear Regression 3\n",
    "\n",
    "Linear regression with the GrLivArea dropped from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's rerun the linear regression without GrLivArea. Create train and test sets again.\n",
    "\n",
    "X = df[df.columns[-8:]]\n",
    "\n",
    "#Split train_sub into train and test and fit 2nd linear model on train:\n",
    "\n",
    "try:  # train_test_split was moved in 0.18.0\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except:  # Following import works through 0.19 but outputs a warning in 0.18\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3rd Linear Regression. RMSE goes up again.\n",
    "\n",
    "ols = linear_model.LinearRegression()\n",
    "\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "y_predicted_train = ols.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_predicted)\n",
    "rms_train = sqrt(mean_squared_error(y_train, y_predicted_train))\n",
    "\n",
    "y_predicted_test = ols.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_predicted_test)\n",
    "rms_test = sqrt(mean_squared_error(y_test, y_predicted_test))\n",
    "\n",
    "print(\"Root mean squared error for train set: %f\" %rms_train)\n",
    "print(\"R^2 for train set: %f\" %ols.score(X_train, y_train))\n",
    "\n",
    "print(\"*\"*50)\n",
    "\n",
    "print(\"Root mean squared error for test set: %f\" %rms_test)\n",
    "print(\"R^2 for test  set: %f\" %ols.score(X_test, y_test))\n",
    "\n",
    "colnames = X_train.columns\n",
    "result = pd.DataFrame(ols.coef_)\n",
    "result.columns = colnames.tolist()\n",
    "result['intercept'] = ols.intercept_ \n",
    "result = result.transpose()\n",
    "result.columns = ['coefficient']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Performing same analysis as above using Statsmodel. Notice AIC and BIC better than 1st linear regression model\n",
    "#but worse than 2nd model. However, we can be rest assured that multicollinearity is not an issue.\n",
    "X_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"eda_cars\"></a></p>\n",
    "\n",
    "## EDA and Feature Engineering of GarageCars\n",
    "\n",
    "Before substituting GarageCars for GrLivArea, the following EDA analyses were performed to assess its \n",
    "relationship with the other variables. GarageCars is then dummified and assessed for its multicollinearity\n",
    "with the other variables using a VIF analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#What if we include GarageCars in the model? Does this improve it? First, let's see what it's correlation is \n",
    "#like with the other explanatory variables.\n",
    "\n",
    "#GarageCars does seem to be correlated with the neighborhood groups.\n",
    "\n",
    "cars_hood_table = pd.crosstab(index=train_sub[\"Neigh_Group\"], \n",
    "                          columns=train_sub[\"GarageCars\"])\n",
    "cars_hood_table.plot(kind=\"bar\", \n",
    "                 figsize=(6,6),\n",
    "                 stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Not so much with House_Group.\n",
    "cars_house_table = pd.crosstab(index=train_sub[\"House_Group\"], \n",
    "                          columns=train_sub[\"GarageCars\"])\n",
    "cars_house_table.plot(kind=\"bar\", \n",
    "                 figsize=(6,6),\n",
    "                 stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#High quality homes have more garages it seems on average\n",
    "cars_quality_table = pd.crosstab(index=train_sub[\"Qual_Group\"], \n",
    "                          columns=train_sub[\"GarageCars\"])\n",
    "cars_quality_table.plot(kind=\"bar\", \n",
    "                 figsize=(6,6),\n",
    "                 stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Inconclusive relationship between GarageCars and SaleCond\n",
    "cars_salecond_table = pd.crosstab(index=train_sub[\"SaleCond_Group\"], \n",
    "                          columns=train_sub[\"GarageCars\"])\n",
    "cars_salecond_table.plot(kind=\"bar\", \n",
    "                 figsize=(6,6),\n",
    "                 stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Does substituting GarageCars for GrFlrArea reduce RMSE while not creating multicollinearity issues? First,\n",
    "#let's dummify the variable\n",
    "df = df.copy()\n",
    "cars = pd.get_dummies(df['GarageCars'], prefix='Cars', prefix_sep='__')\n",
    "cars = cars.drop('Cars__0', axis=1)\n",
    "df = pd.concat([df, cars], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split train_sub into train and test and fit 2nd linear model on train:\n",
    "\n",
    "X = df[df.columns[-12:]]\n",
    "\n",
    "try:  # train_test_split was moved in 0.18.0\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except:  # Following import works through 0.19 but outputs a warning in 0.18\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Checking VIFs. Amazing: all the VIFs are low. (Too good to be true????)\n",
    "vif = [variance_inflation_factor(X.values, i) for \n",
    "       i in range(X.shape[1])]\n",
    "print(\"VIF for all the variables:\")\n",
    "list(zip(vif, X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"linear4\"></a></p>\n",
    "\n",
    "## Linear Regression 4\n",
    "\n",
    "Linear regression using the following variables: \"GarageCars\", \"Neighborhood\", \"OverallQual\", \n",
    "\"HouseStyle\", \"SaleCondition\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4th Linear Regression. RMSE goes down from 3rd model.\n",
    "\n",
    "ols = linear_model.LinearRegression()\n",
    "\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "y_predicted_train = ols.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_predicted)\n",
    "rms_train = sqrt(mean_squared_error(y_train, y_predicted_train))\n",
    "\n",
    "y_predicted_test = ols.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_predicted_test)\n",
    "rms_test = sqrt(mean_squared_error(y_test, y_predicted_test))\n",
    "\n",
    "print(\"Root mean squared error for train set: %f\" %rms_train)\n",
    "print(\"R^2 for train set: %f\" %ols.score(X_train, y_train))\n",
    "\n",
    "print(\"*\"*50)\n",
    "\n",
    "print(\"Root mean squared error for test set: %f\" %rms_test)\n",
    "print(\"R^2 for test  set: %f\" %ols.score(X_test, y_test))\n",
    "\n",
    "colnames = X_train.columns\n",
    "result = pd.DataFrame(ols.coef_)\n",
    "result.columns = colnames.tolist()\n",
    "result['intercept'] = ols.intercept_ \n",
    "result = result.transpose()\n",
    "result.columns = ['coefficient']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Performing same analysis as above using Statsmodel. AIC and BIC numbers improve relative to 3rd model and \n",
    "#multi-collinearity doesn't seem to be an issue. \n",
    "X_train = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
